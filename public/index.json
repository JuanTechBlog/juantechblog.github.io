[{"content":"I want to create a bot that can congratulate other Telegram group members when they make a profit from crypto investments (Please do your own research before making any investments).\nI keep the Telegram bot\u0026rsquo;s function simple. Group members can instruct the bot using command( /gx ) and mention( @ ) a user. The bot will then reply a prefixed congratulatory message and attach with a random GIF.\nHow to Create a Telegram Bot? I don\u0026rsquo;t really know.\nI once create a Telegram bot for a school coursework. I wrote the backend program in python and ran it on my laptop.\nNow, the Telegram group members are from different countries and time zones, so the bot should be available for 24/7. I don\u0026rsquo;t want to keep my computer running all the time, so I\u0026rsquo;m considering different approach. \u0026ldquo;Serverless\u0026rdquo; came to my mind—it allows the Telegram bot code to run on the cloud 24/7 and on demand.\nMy plan is straightforward. I will use JavaScript to write the code, Cloudflare Workers (a serverless service) to run the code, and Cloudflare Workers KV(a cloud data storage) to store some GIF URLs.\nLet\u0026rsquo;s begin.\nPrerequisite A Telegram account. A Cloudflare account. Create a Telegram Bot. To create a Telegram bot, we need to talk to the BotFather.\nGo to BotFather , type /newbot, or click Menu and select /newbot. Enter your bot\u0026rsquo;s name(e.g., GX Bot). Enter your bot\u0026rsquo;s username(e.g., gx-box). BotFather will then provide you with an HTTP API token. The HTTP API token is important and will be used to control the bot we just created.\nSetup Telegram Bot Command and Group Privacy. Next, we pre-define a command in our Telegram bot to make it easier for users.\nType /mybot and select our bot(e.g., gx-bot). Choose Edit Bot and then Edit Commands. Enter the command following the format provided by BotFather\u0026rsquo;s prompt. (e.g., gx - 加 @ 用户 Bot 就会帮你恭喜群友). Also, disable the Telegram bot\u0026rsquo;s group privacy settings to allow all message flows to the bot backend without requiring group admin right.\nType /mybot and select our bot (e.g., gx-bot). Select Bot Settings and Group Privacy. Click Turn off. Create a Cloudflare Workers. Log in to Cloudflare. Go to Workers \u0026amp; Pages in the left side menu and click the Overview. Click the Create, then select Create Worker under the Workers tab. Enter a name(e.g., gx-bot-worker) for the worker and click Deploy. Once it\u0026rsquo;s done, click the Continue to Project button. The worker is now ready to serve. It\u0026rsquo;s just waiting for us to provide the code to run. We will click the Edit Code button later to paste the code. Before that, we will need to set up Cloudflare Workers KV to store our GIF URLs.\nCreate and Set Up Cloudflare Workers KV. We will use Cloudflare Workers KV to store the GIF URLs, which will be included in the Telegram bot response.\nClick the down arrow next to Workers \u0026amp; Pages on the left, and then click the KV. Click Create a Namespace, enter a Namespace Name(e.g., kv-gifs), and click Add. Afterward, the new Namespace will be added to the table blow. Click View in the row of the Namespace we just created. Go to the KV Pairs tab, and enter the key and value as shown in the table below. Key Value gifs [\u0026quot;https://media1.tenor.com/m/-ZQ-I0N9dRwAAAAC/dog-cute-dog.gif\u0026quot;,\u0026quot;https://media.tenor.com/WIMffkKhJC0AAAAi/pig-dog.gif\u0026quot;] You can always replace the values with your own GIF URLs.\nCloudflare KV stores data in key-value pairs. Our value will be the URLs in JSON array format, and we will use gifts as the key to retrieve it.\nClick Add entry to save. Binding Cloudflare Workers KV and Variables/Secrets in Cloudflare Workers. To use Cloudflare KV in the worker, we need to bind the services together first. Additionally, we will bind our HTTP API token and two secret variables.\nClick the down arrow next to Workers \u0026amp; Pages at the left and select Overview. Click the name of the worker(e.g., gx-bot-worker, from the previous example) we just created earlier. Go to the Settings tab. Binding Cloudflare KV Under Bindings, click the + Add. Click KV namespace(e.g., kv-gifs, from the previous example). Enter a Variable name(e.g., GIFS), choose the KV namespace we just created, and click Deploy. Add Variables and Secrets We will create two variables according to the table below:\nVariable Name Value ENV_BOT_TOKEN \u0026lt;HTTP API token from BotFather\u0026gt; ENV_BOT_SECRET \u0026lt;A Random combination of A-Z, a-z, 0-9, _ and -\u0026gt; ENV_BOT_TOKEN will store our HTTP API token. For ENV_BOT_SECRET, we need to create a value as a secret key to verify each Telegram updates.\nUnder Variables and Secrets, click +Add. The Type can remain as text or be changed to secret to encrypt the text. Enter the Variable Name and Value according to the table above. Click Deploy. Coding I will fork the code from telegram-bot-cloudflare by cvzi and then make some modifications to fit our case.\nFirst, we will declare some variables and constants.\nlet TOKEN; // Get it from @BotFather https://core.telegram.org/bots#6-botfather let SECRET; // A-Z, a-z, 0-9, _ and - let ENV_VAL; // Enviroment const WEBHOOK = \u0026#39;/endpoint\u0026#39;; const BOT_COM = \u0026#39;bot_command\u0026#39;; const GX_COM = \u0026#39;/gx\u0026#39;; const MENTION = \u0026#39;mention\u0026#39;; const TXT_MENTION = \u0026#39;text_mention\u0026#39;; We will create an entry point for the worker to receive and process requests from the Telegram bot API.\nexport default { async fetch(request, env) { ENV_VAL = env; TOKEN = env.ENV_BOT_TOKEN; SECRET = env.ENV_BOT_SECRET; return await route(request); }, }; The Workers runtime will inject the KV bindings, variables and secrets in the env. We assign them to our variables accordingly and pass the request to the route function.\nThe route function will direct the request to be processed with handleWebhook or set up our worker using the registerWebhook and unRegisterWebhook functions.\n/** * Wait for requests to the worker */ async function route (request) { const url = new URL(request.url) if (url.pathname === WEBHOOK) { return await handleWebhook(request); } else if (url.pathname === \u0026#39;/registerWebhook\u0026#39;) { return await registerWebhook(request, url, WEBHOOK, SECRET); } else if (url.pathname === \u0026#39;/unRegisterWebhook\u0026#39;) { return await unRegisterWebhook(request); } else { return await new Response(\u0026#39;No handler for this request\u0026#39;); } } The registerWebhook function will notify our endpoint URL and ENV_BOT_SECRET to the Telegram Bot API for receiving new updates. Obviously, the unRegisterWebhook function undoes this.\n/** * Set webhook to this worker\u0026#39;s url * https://core.telegram.org/bots/api#setwebhook */ async function registerWebhook (request, requestUrl, suffix, secret) { // https://core.telegram.org/bots/api#setwebhook const webhookUrl = `${requestUrl.protocol}//${requestUrl.hostname}${suffix}` const r = await (await fetch(apiUrl(\u0026#39;setWebhook\u0026#39;, { url: webhookUrl, secret_token: secret }))).json() return new Response(\u0026#39;ok\u0026#39; in r \u0026amp;\u0026amp; r.ok ? \u0026#39;Ok\u0026#39; : JSON.stringify(r, null, 2)) } /** * Remove webhook * https://core.telegram.org/bots/api#setwebhook */ async function unRegisterWebhook (request) { const r = await (await fetch(apiUrl(\u0026#39;setWebhook\u0026#39;, { url: \u0026#39;\u0026#39; }))).json() return new Response(\u0026#39;ok\u0026#39; in r \u0026amp;\u0026amp; r.ok ? \u0026#39;Ok\u0026#39; : JSON.stringify(r, null, 2)) } The handleWebhook function will check the incoming request\u0026rsquo;s secret token from Telegram Bot API against our ENV_BOT_SECRET. After that, it will convert request to JSON format and forward it to onUpdate function.\n/** * Handle requests to WEBHOOK * https://core.telegram.org/bots/api#update */ async function handleWebhook (request) { // Check secret if (request.headers.get(\u0026#39;X-Telegram-Bot-Api-Secret-Token\u0026#39;) !== SECRET) { return new Response(\u0026#39;Unauthorized\u0026#39;, { status: 403 }) } // Read request body synchronously const update = await request.json() // Deal with response asynchronously await onUpdate(update); return new Response(\u0026#39;Ok\u0026#39;) } The onUpdate function checks whether the message object exists in the update. if it does, the function forwards the message to onMessage.\n/** * Handle incoming Update * https://core.telegram.org/bots/api#update */ async function onUpdate (update) { if (\u0026#39;message\u0026#39; in update) { await onMessage(update.message) } } The onMessage function will perform several checks:\nCheck whether the entities object exists in the message. Check whether one of the entities\u0026rsquo;s types is BOT_COM. Find the mentionedUser in the entities through the entities\u0026rsquo;s type of MENTION or TXT_MENTION. Check whether the command is valid. If all the checks pass, extract the username, substitute it into a template string, and pass it to the sendAnimationAndText function. /** * Handle incoming Message * https://core.telegram.org/bots/api#message */ function onMessage (message) { if (!(\u0026#39;entities\u0026#39; in message)) { return; } let validComm = false; let hasBotComm = message.entities.some(entity =\u0026gt; entity.type === BOT_COM); let mentionedUser = message.entities.find(entity =\u0026gt; entity.type === MENTION || entity.type === TXT_MENTION); if (hasBotComm) { validComm = message.text.startsWith(GX_COM) } if (hasBotComm \u0026amp;\u0026amp; validComm \u0026amp;\u0026amp; mentionedUser) { let text = message.text; let mentionedUsername = text.slice(mentionedUser.offset, mentionedUser.offset + mentionedUser.length); let response = `恭喜群友 ${mentionedUsername} 赚钱`; return sendAnimationAndText(message.chat.id, response); } return; } The sendAnimationAndText function will retrieve the list of gifs from KV and randomly pick a URL from it. Afterwards, it will pass all the parameters to apiUrl to form a query string and send it as a response to the Telegram Bot API.\n/** * Send plain text message * https://core.telegram.org/bots/api#sendmessage */ async function sendAnimationAndText (chatId, text) { let gifs = JSON.parse(await ENV_VAL.GIFS.get(\u0026#34;gifs\u0026#34;)); let randomGif = gifs[Math.floor(Math.random() * gifs.length)]; return (await fetch(apiUrl(\u0026#39;sendAnimation\u0026#39;, { chat_id: chatId, animation: randomGif, caption: text }))).json() } The apiUrl is a utility function that converts the passed-in parameters to query strings.\n/** * Return url to telegram api, optionally with parameters added */ function apiUrl (methodName, params = null) { let query = \u0026#39;\u0026#39; if (params) { query = \u0026#39;?\u0026#39; + new URLSearchParams(params).toString() } return `https://api.telegram.org/bot${TOKEN}/${methodName}${query}` } Full code /** * Original source code: https://github.com/cvzi/telegram-bot-cloudflare * with some modification by YJCHOO */ let TOKEN; // Get it from @BotFather https://core.telegram.org/bots#6-botfather let SECRET; // A-Z, a-z, 0-9, _ and - let ENV_VAL; const WEBHOOK = \u0026#39;/endpoint\u0026#39;; const BOT_COM = \u0026#39;bot_command\u0026#39;; const GX_COM = \u0026#39;/gx\u0026#39;; const MENTION = \u0026#39;mention\u0026#39;; const TXT_MENTION = \u0026#39;text_mention\u0026#39;; export default { async fetch(request, env) { ENV_VAL = env; TOKEN = env.ENV_BOT_TOKEN; SECRET = env.ENV_BOT_SECRET; return await route(request); }, }; /** * Wait for requests to the worker */ async function route (request) { const url = new URL(request.url); if (url.pathname === WEBHOOK) { return await handleWebhook(request); } else if (url.pathname === \u0026#39;/registerWebhook\u0026#39;) { return await registerWebhook(request, url, WEBHOOK, SECRET); } else if (url.pathname === \u0026#39;/unRegisterWebhook\u0026#39;) { return await unRegisterWebhook(request); } else { return await new Response(\u0026#39;No handler for this request\u0026#39;); } } /** * Handle requests to WEBHOOK * https://core.telegram.org/bots/api#update */ async function handleWebhook (request) { // Check secret if (request.headers.get(\u0026#39;X-Telegram-Bot-Api-Secret-Token\u0026#39;) !== SECRET) { return new Response(\u0026#39;Unauthorized\u0026#39;, { status: 403 }); } // Read request body synchronously const update = await request.json(); // Deal with response asynchronously await onUpdate(update); return new Response(\u0026#39;Ok\u0026#39;); } /** * Handle incoming Update * https://core.telegram.org/bots/api#update */ async function onUpdate (update) { if (\u0026#39;message\u0026#39; in update) { await onMessage(update.message); } } /** * Handle incoming Message * https://core.telegram.org/bots/api#message */ function onMessage (message) { if (!(\u0026#39;entities\u0026#39; in message)) { return; } let validComm = false; let hasBotComm = message.entities.some(entity =\u0026gt; entity.type === BOT_COM); let mentionedUser = message.entities.find(entity =\u0026gt; entity.type === MENTION || entity.type === TXT_MENTION); if (hasBotComm) { validComm = message.text.startsWith(GX_COM); } if (hasBotComm \u0026amp;\u0026amp; validComm \u0026amp;\u0026amp; mentionedUser) { let text = message.text; let mentionedUsername = text.slice(mentionedUser.offset, mentionedUser.offset + mentionedUser.length); let response = `恭喜群友 ${mentionedUsername} 赚钱`; return sendAnimationAndText(message.chat.id, response); } return; } /** * Send plain text message * https://core.telegram.org/bots/api#sendmessage */ async function sendAnimationAndText (chatId, text) { let gifs = JSON.parse(await ENV_VAL.GIFS.get(\u0026#34;gifs\u0026#34;)); let randomGif = gifs[Math.floor(Math.random() * gifs.length)]; return (await fetch(apiUrl(\u0026#39;sendAnimation\u0026#39;, { chat_id: chatId, animation: randomGif, caption: text }))).json() } /** * Set webhook to this worker\u0026#39;s url * https://core.telegram.org/bots/api#setwebhook */ async function registerWebhook (request, requestUrl, suffix, secret) { // https://core.telegram.org/bots/api#setwebhook const webhookUrl = `${requestUrl.protocol}//${requestUrl.hostname}${suffix}`; const r = await (await fetch(apiUrl(\u0026#39;setWebhook\u0026#39;, { url: webhookUrl, secret_token: secret }))).json(); return new Response(\u0026#39;ok\u0026#39; in r \u0026amp;\u0026amp; r.ok ? \u0026#39;Ok\u0026#39; : JSON.stringify(r, null, 2)); } /** * Remove webhook * https://core.telegram.org/bots/api#setwebhook */ async function unRegisterWebhook (request) { const r = await (await fetch(apiUrl(\u0026#39;setWebhook\u0026#39;, { url: \u0026#39;\u0026#39; }))).json(); return new Response(\u0026#39;ok\u0026#39; in r \u0026amp;\u0026amp; r.ok ? \u0026#39;Ok\u0026#39; : JSON.stringify(r, null, 2)); } /** * Return url to telegram api, optionally with parameters added */ function apiUrl (methodName, params = null) { let query = \u0026#39;\u0026#39;; if (params) { query = \u0026#39;?\u0026#39; + new URLSearchParams(params).toString(); } return `https://api.telegram.org/bot${TOKEN}/${methodName}${query}`; } Testing Now, it\u0026rsquo;s time to test the bot.\nSearch our bot, click start and type command.\nAdd the bot to our group chat and test it.\n","permalink":"http://localhost:1313/posts/create-telegram-bot-using-javascript-cloudflare-workers-cloudflare-workers-kv/","summary":"\u003cp\u003eI want to create a bot that can congratulate other Telegram group members when they make a profit from crypto investments \u003cstrong\u003e(Please do your own research before making any investments)\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eI keep the Telegram bot\u0026rsquo;s function simple. Group members can instruct the bot using command( \u003cstrong\u003e/gx\u003c/strong\u003e ) and mention( \u003cstrong\u003e@\u003c/strong\u003e ) a user. The bot will then reply a prefixed congratulatory message and attach with a random GIF.\u003c/p\u003e\n\u003ch2 id=\"how-to-create-a-telegram-bot\"\u003eHow to Create a Telegram Bot?\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eI don\u0026rsquo;t really know.\u003c/p\u003e","title":"Create a Telegram Bot using JavaScript, Cloudflare Workers and Cloudflare Workers KV."},{"content":"Let\u0026rsquo;s start with my PC spec.\nComponents Parts Processor Intel i5 10400ES iGPU Intel UHD Graphics 630 Motherboard AsRock B460M Pro RAM Adata DDR4-2666 4GB x2 dGPU N/A When it comes to AI, most people probably think it requires a beefy GPU to run smoothly and quickly. And that\u0026rsquo;s true. But just how bad will it be when running AI on a low-end GPU?\nHow to run LLM and Stable Diffusion on Intel UHD 630 iGPU? Intel has a Pytouch library called IPEX-LLM for running LLM on Intel CPU and GPU. However, it doesn’t seem to support my iGPU.\nThe IPEX-LLM requires a graphic driver version of 31.0.101.5122 and higher, which is only compatible with Intel Core 11 gen and newer iGPUs, as well as Intel Arc GPUs. For the Intel UHD 630, the latest driver available is 31.0.101.2130—below the required level.\nSo, I’m looking for alternative options. I think Vulkan might be the only way to get LLM and Stable Diffusion running on my GPU.\nLLM Test Run (Llama 3.2 1B Instruct Q8 Llama 3.2 3B Instruct Q8) Let\u0026rsquo;s run some Large Language Model(LLM). I used Jan, a software that support Vulkan, to run open LLMs. I will test run the Llama 3.2 1B Instruct Q8 and Llama 3.2 3B Instruct Q8.\nDownload and install Jan. Go the Settings → Advanced Settings → toggle Experimental Mode → toggle Vulkan Support. Go the Hub, download Llama 3.2 1B Instruct Q8 and Llama 3.2 3B Instruct Q8. Then, we can start using these models. First Attempt on iGPU I run the Llama 3.2 1B Instruct Q8 on my iGPU and asked it, \u0026ldquo;List down what you can do for me\u0026rdquo;.\nThe iGPU utilization almost hit 100% while generating the response.\nThe token speed is around 7.7t/s, which is fairly usable.\nSecond Attempt on iGPU Next, I switch the model to Llama 3.2 3B Instruct Q8 and run it.\nThe model can't even start—it failed to allocate memory due to insufficient device memory, as noted in the log.\nThe Llama 3.2 3B Instruct Q8 require at least 8GB VRAM. My iGPU only got 4GB shared VRAM. Obviously, I don\u0026rsquo;t have enough RAM to share with my iGPU.\nThird Attempt on CPU Why not try the CPU instead? I toggle off the Vulkan support and run Llama 3.2 1B Instruct Q8 on the CPU.\nCPU utilization is between 80% and 90% during response generation.\nWoW! The token speed is double up to 14.46t/s, which is faster than the iGPU.\nFourth Attempt on CPU I continue try the Llama 3.2 3B Instruct Q8 on the CPU. This time, the model able to start and generate response.\nCPU utilization close to 100% while generating response.\nThe token speed is about 5.56t/s, which is a bit slow but still usable.\nStable Diffusion Test Run (SD 1.5) To run Stable Diffusion on the iGPU, I use the stable-diffusion.cpp version that supports Vulkan.\nFirst Attempt on iGPU I run the Vulkan-supported stable-diffusion.cpp executable with Stable Diffusion 1.5 model and using a simple prompt, \u0026quot;people\u0026quot;, with default settings.\nThe iGPU utilization is around 100%.\nIt takes 551.46s(≈ 9 minutes and 11 seconds) to complete and the speed is 28.09s/it.\nSecond Attempt on CPU - AVX2 I then download the CPU AVX2-supported stable-diffusion.cpp. I run it with Stable Diffusion 1.5 model and a simple prompt, \u0026quot;people\u0026quot;. All the settings remain default.\nThe CPU utilization is around 66% only.\nIt take 352.32s(≈ 5 minutes and 52 seconds) to complete with the speed of 16.41s/it.—nearly twice as fast as the iGPU.\nConclusion Thanks to Vulkan, I can play a little bit of AI things on my low-end iGPU. However, when looking at token speed or iteration times, the CPU outperforms the iGPU by nearly double, which making almost no sense to use iGPU for AI tasks.\nThe only use case I can imagine is offload some of the workload from the CPU . For example, if I\u0026rsquo;m coding and need a LLM to help debug, I could let the iGPU handle the LLM responses while the CPU focuses on compiling code.\nLastly, it\u0026rsquo;s quite fun to play around AI.\n","permalink":"http://localhost:1313/posts/run-local-llm-stable-diffusion-locally-low-end-hardware/","summary":"Try running Llama 3.2 1B Q8, Llama 3.2 3B Q8 \u0026amp; Stable Diffusion 1.5 on Intel UHD Graphics 630. Also, try to run AI models on the CPU.","title":"Running LLM and Stable Diffusion Locally on My Low-End Hardware"},{"content":"Recently, I started working with the ESP-01S module and CH340 ESP programmer. However, when I tried to upload a new Arduino sketch, I encountered an error:\nA fatal esptool.py error occurred: Cannot configure port, something went wrong. Original message: PermissionError(13, \u0026#39;A device attached to the system is not functioning.\u0026#39;, None, 31) CH340 Driver Issue and Fix. After some googling, I discovered that the problem was related to the CH340 USB-to-serial chip driver. The latest CH340 driver, version 3.8, seem to cause the issue. To fix it, I had to uninstall the 3.8 version driver, and install the previous 3.4 version driver.\nHere how you can do the same:\nGo to Device Manager and find USB-SERIAL CH340 under Ports(COM \u0026amp; LPT). Right the CH340 device and click Properties. The driver version is under Driver tab. If the version is not right, click the Uninstall Device. Download the 3.4 version and install. Windows 11 Auto Update Drive, Break the CH340 Driver Again. Somehow, Windows 11 will automatically update drivers, and this can revert the CH340 driver back to the problematic version 3.8. My temporary fix is to disable automatic driver updates.\nPress the Windows key and search for Change device installation settings. Click on the search result to open the settings. Select No radio button. Click Save Changes. Please note that disabling this stops Windows install/update any new and existing device drivers automatically. Make sure you install or update your driver manually.\n","permalink":"http://localhost:1313/posts/how-to-fix-ch340-driver-3-8-issue/","summary":"\u003cp\u003eRecently, I started working with the ESP-01S module and CH340 ESP programmer. However, when I tried to upload a new Arduino sketch, I encountered an error:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-shell\" data-lang=\"shell\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eA fatal esptool.py error occurred: Cannot configure port, something went wrong. Original message: PermissionError\u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003e13, \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;A device attached to the system is not functioning.\u0026#39;\u003c/span\u003e, None, 31\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"ch340-driver-issue-and-fix\"\u003eCH340 Driver Issue and Fix.\u003c/h2\u003e\n\u003cp\u003eAfter some googling, I discovered that the problem was related to the CH340 USB-to-serial chip driver. The latest CH340 driver, version 3.8, seem to cause the issue. To fix it, I had to uninstall the 3.8 version driver, and install the previous 3.4 version driver.\u003c/p\u003e","title":"How to Fix CH340 USB to Serial Driver 3.8 version issue."},{"content":" I built the same monitor riser/stand two years ago. After that, I upgraded to a monitor arm. I gave my monitor riser to my sister.\nNot long ago, I bought an IKEA ALEX storage unit to replace one side of my table legs. My tabletop doesn\u0026rsquo;t fit the pre-drilled holes for the ALEX storage unit, so I just placed the tabletop on top of the ALEX storage unit. It\u0026rsquo;s not secure and can move easily.\nTherefore, I don\u0026rsquo;t think the monitor arm is safe to use in this setup anymore. I need to built a monitor riser.\n","permalink":"http://localhost:1313/posts/easy-diy-monitor-riser-stand/","summary":"\u003cdiv style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"\u003e\n      \u003ciframe allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen\" loading=\"eager\" referrerpolicy=\"strict-origin-when-cross-origin\" src=\"https://www.youtube.com/embed/En6yiZQn0ZY?autoplay=0\u0026amp;controls=1\u0026amp;end=0\u0026amp;loop=0\u0026amp;mute=0\u0026amp;start=0\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" title=\"YouTube video\"\u003e\u003c/iframe\u003e\n    \u003c/div\u003e\n\n\u003cp\u003eI built the same monitor riser/stand two years ago. After that, I upgraded to a monitor arm. I gave my monitor riser to my sister.\u003c/p\u003e\n\u003cp\u003eNot long ago, I bought an IKEA ALEX storage unit to replace one side of my table legs. My tabletop doesn\u0026rsquo;t fit the pre-drilled holes for the ALEX storage unit, so I just placed the tabletop on top of the ALEX storage unit. It\u0026rsquo;s not secure and can move easily.\u003c/p\u003e","title":"Easy DIY Monitor Riser/Stand."},{"content":"I know a ready-made LED controller is affordable. But I think ESP32 with WLED is more versatile and playable. I can integrate it into my Home Assistant and TV ambient light project later.\nLet\u0026rsquo;s get started.\nVideo Parts Required 5M WS2812B 30LED/M LED Light Strip(Get any desire length). ESP 32(Any ESP8266/ESP32). 5V6A Power Supply. DC Jack. Breadboard. Some Jumper Wires. Flash WLED We will use the easy way, ESP Web Tools, to flash the WLED firmware into ESP32. However, it requires using Google Chrome/Microsoft Edge browser and serial driver for your development board.\nGo to Install WLED page, select the latest version, and click the Install button.\nSelect the ESP32\u0026rsquo;s series port.\nClick Install WLED\nWe can continue wiring up other parts.\nAfter the installation, set up the Wi-Fi connection and log on to the WLED web UI. Now, we can continue wiring up other parts.\nWire-up WS2812B ESP32 DC Jack RX2(GPI16) RX2(GPIO16) +5V VIN + GND GND - The WS2812B has two ways to power it; one from the red and white wires or the 3-pin connector. The Power supply plug with the DC jack connects to the WS2812B\u0026rsquo;s red(+) and white(GND) wires.\nESP32\u0026rsquo;s VIN, RX2(GPIO16), and GND connect with the WS2812B\u0026rsquo;s 3-pin connector.\nIt\u0026rsquo;s a common recommendation to put a 100 ~ 1000uF capacitor close to the WS2812B\u0026rsquo;s +5V and GND pins. Also, a 220 ~ 470 Ω resistor is added near the WS2812B\u0026rsquo;s data pin. Both addon for protection and signal stability purposes.\nResult WS2812B in blends effect with Analogous color palette controlled by ESP32 and WLED\n","permalink":"http://localhost:1313/posts/diy-ws2812b-led-light-strip-controller-esp32-wled/","summary":"\u003cp\u003eI know a ready-made LED controller is affordable. But I think ESP32 with WLED is more versatile and playable. I can integrate it into my Home Assistant and TV ambient light project later.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s get started.\u003c/p\u003e\n\u003ch2 id=\"video\"\u003eVideo\u003c/h2\u003e\n\u003cdiv style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"\u003e\n      \u003ciframe allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen\" loading=\"eager\" referrerpolicy=\"strict-origin-when-cross-origin\" src=\"https://www.youtube.com/embed/GwjAe-mXsfs?autoplay=0\u0026amp;controls=1\u0026amp;end=0\u0026amp;loop=0\u0026amp;mute=0\u0026amp;start=0\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" title=\"YouTube video\"\u003e\u003c/iframe\u003e\n    \u003c/div\u003e\n\n\u003ch2 id=\"parts-required\"\u003eParts Required\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e5M WS2812B 30LED/M LED Light Strip(Get any desire length).\u003c/li\u003e\n\u003cli\u003eESP 32(Any ESP8266/ESP32).\u003c/li\u003e\n\u003cli\u003e5V6A Power Supply.\u003c/li\u003e\n\u003cli\u003eDC Jack.\u003c/li\u003e\n\u003cli\u003eBreadboard.\u003c/li\u003e\n\u003cli\u003eSome Jumper Wires.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"flash-wled\"\u003eFlash WLED\u003c/h2\u003e\n\u003cp\u003eWe will use the easy way, ESP Web Tools, to flash the WLED firmware into ESP32. However, it requires using Google Chrome/Microsoft Edge browser and serial driver for your development board.\u003c/p\u003e","title":"DIY WS2812B Addressable LED Light Strip Controller with ESP32 and WLED."},{"content":"I recently switched from macOS(Hackintosh) to Windows 11. So, a lot of things need to be installed again. Hugo is one of the tools that I use to preview my blog posts or edit some theme settings.\nTo install the Hugo extended edition, we will only install Go/Golang and Git.\nLet\u0026rsquo;s install it.\nInstall Go/Golang Download the Go/Golang installer from the Go website.\nRun it and proceed until complete.\nTo check the installation by executing the command below:\n\u0026gt; go version The result should be something like this:\ngo version go1.22.1 windows/amd64 Install Git Download the Git installer from the official website.\nRun it and proceed until complete. Most of the settings are default, I only change the text editor to Visual Studio Code.\nAfterward, we open the terminal to verify the installation as below:\n\u0026gt; git --version The result should be something like this:\ngit version 2.44.0.windows.1 Install Hugo Download the Hugo extended edition binary from Hugo\u0026rsquo;s GitHub repository.\nExtract the binary\u0026rsquo;s compressed file. I take a further step to place it in the Program Files, Disk C, and copy the folder path.\nPress the Win key, search \u0026ldquo;Edit the system environment variables\u0026rdquo;, and press Open.\nClick the Environment Variables button, select Path, and click the edit button in the User Variables section.\nClick the New button and paste the Hugo extended edition binary\u0026rsquo;s folder path.\nClick the OK button twice to save the changes.\nOpen the terminal and execute this command to verify the installation.\n\u0026gt; hugo version The result should be something like this:\nhugo v0.123.8-5fed9c591b694f314e5939548e11cc3dcb79a79c windows/amd64 BuildDate=2024-03-07T13:14:42Z VendorInfo=gohugoio ","permalink":"http://localhost:1313/posts/install-hugo-windows-11/","summary":"\u003cp\u003eI recently switched from macOS(Hackintosh) to Windows 11. So, a lot of things need to be installed again. Hugo is one of the tools that I use to preview my blog posts or edit some theme settings.\u003c/p\u003e\n\u003cp\u003eTo install the Hugo extended edition, we will only install Go/Golang and Git.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s install it.\u003c/p\u003e\n\u003ch2 id=\"install-gogolang\"\u003eInstall Go/Golang\u003c/h2\u003e\n\u003cp\u003eDownload the Go/Golang installer from the Go \u003ca href=\"https://go.dev/dl/\"\u003ewebsite\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eRun it and proceed until complete.\u003c/p\u003e\n\u003cp\u003eTo check the installation by executing the command below:\u003c/p\u003e","title":"How to install Hugo on Windows 11."},{"content":"The photo above is my cheap human presence sensor with ESP8266 and LD2410C mmWave radar sensor. It costs about RM 27—ESP8266-RM 9.90 and LD2410C-RM 17.61.\nThis is my first time using ESPHome and LD2410. The LD2410C mmWave radio sensor module comes with Bluetooth connectivity, and Home Assistant has an integration for this sensor module. We can power the LD2410C and directly integrate the sensor module into Home Assistant via Bluetooth.\nSomehow, the Bluetooth connection between the Home Assistant and LD2410C is unstable and breaks every few minutes. Therefore, I use an ESP8266 hook with LD2410C, run ESPHome, and integrate it into Home Assistant via Wi-Fi.\nLet\u0026rsquo;s build it.\nParts Required ESP8266 development board - Also, any ESP32 development. HLK-LD2410C mmWave Radar Sensor Module - Any LD2410 variant. A few jumper wires. USB Cable. Breadboard - if necessary. Power Adapter - if necessary. Flash ESPHome into ESP8266 We will use the ESPHome\u0026rsquo;s install ready-made project method to flash the firmware into our ESP8266 development board and adopt it in the ESPHome Dashboard. This method only works with Chrome and Microsoft Edge browsers. Also, it may need the development board\u0026rsquo;s USB driver.\nConnect ESP8266 to the computer via a USB cable. Log on to ESPHome\u0026rsquo;s web page. Select Empty ESPHome device under the I want to create a: section, pick ESP32/ESP8266 under the manufacturer of the device you want to set up section, and click CONNECT button. Select the corresponding USB serial port in the pop-out window. Click the INSTALL ESPHOME WEB. Configure the Wi-Fi. After, we can leave the ESP8266 alone, keep it powered, and upload a new configuration(yaml) through wireless in the ESPHome Dashboard later.\nSet up ESPHome Dashboard using Docker Compose Next, We run the ESPHome Dashboard in a Docker container using Docker Compose.\nWe can create a new or modify existing docker-compose.yaml as below:\nThe script below is from the official documentation.\nversion: \u0026#39;3\u0026#39; services: esphome: container_name: esphome image: ghcr.io/esphome/esphome volumes: - /path/to/esphome/config:/config - /etc/localtime:/etc/localtime:ro restart: always privileged: true network_mode: host environment: - USERNAME=ChangeHere - PASSWORD=ChangeHere Remember to change the USERNAME and PASSWORD variables in the environment.\nWe can execute the command below to start the container.\n$ docker compose up -d Once the ESPHome Dashboard is started, we can log on to the web page.\nhttp://\u0026lt;your ip address\u0026gt;:6052/ Adopt ESP8266 in ESPhome Dashboard After logging in to the ESPHome Dashboard, the newly flashed firmware ESP8266 should appear in the dashboard. We click the ADOPT button to adopt the ESP8266. It will take a few minutes to complete.\nLater, click the EDIT button, modify the script as below, and save it:\n# Append code below the captive_portal # ... ... uart: id: uart_ld2410 tx_pin: GPIO1 rx_pin: GPIO3 baud_rate: 256000 parity: NONE stop_bits: 1 ld2410: uart_id: uart_ld2410 binary_sensor: - platform: ld2410 has_target: name: Presence has_moving_target: name: Moving Target has_still_target: name: Still Target sensor: - platform: ld2410 light: name: light moving_distance: name : Moving Distance still_distance: name: Still Distance moving_energy: name: Move Energy still_energy: name: Still Energy detection_distance: name: Detection Distance g0: move_energy: name: g0 move energy still_energy: name: g0 still energy g1: move_energy: name: g1 move energy still_energy: name: g1 still energy g2: move_energy: name: g2 move energy still_energy: name: g2 still energy g3: move_energy: name: g3 move energy still_energy: name: g3 still energy g4: move_energy: name: g4 move energy still_energy: name: g4 still energy g5: move_energy: name: g5 move energy still_energy: name: g5 still energy g6: move_energy: name: g6 move energy still_energy: name: g6 still energy g7: move_energy: name: g7 move energy still_energy: name: g7 still energy g8: move_energy: name: g8 move energy still_energy: name: g8 still energy switch: - platform: ld2410 engineering_mode: name: \u0026#34;engineering mode\u0026#34; bluetooth: name: \u0026#34;control bluetooth\u0026#34; number: - platform: ld2410 timeout: name: timeout light_threshold: name: light threshold max_move_distance_gate: name: max move distance gate max_still_distance_gate: name: max still distance gate g0: move_threshold: name: g0 move threshold still_threshold: name: g0 still threshold g1: move_threshold: name: g1 move threshold still_threshold: name: g1 still threshold g2: move_threshold: name: g2 move threshold still_threshold: name: g2 still threshold g3: move_threshold: name: g3 move threshold still_threshold: name: g3 still threshold g4: move_threshold: name: g4 move threshold still_threshold: name: g4 still threshold g5: move_threshold: name: g5 move threshold still_threshold: name: g5 still threshold g6: move_threshold: name: g6 move threshold still_threshold: name: g6 still threshold g7: move_threshold: name: g7 move threshold still_threshold: name: g7 still threshold g8: move_threshold: name: g8 move threshold still_threshold: name: g8 still threshold button: - platform: ld2410 factory_reset: name: \u0026#34;factory reset\u0026#34; restart: name: \u0026#34;restart\u0026#34; query_params: name: query params text_sensor: - platform: ld2410 version: name: \u0026#34;firmware version\u0026#34; mac_address: name: \u0026#34;mac address\u0026#34; select: - platform: ld2410 distance_resolution: name: \u0026#34;distance resolution\u0026#34; baud_rate: name: \u0026#34;baud rate\u0026#34; light_function: name: light function Then, we click the VALIDATE button in the ⋮(three vertical dots button) to ensure the script is valid.\nHit the INSTALL button in n the ⋮(three vertical dots button) to upload the new configuration into ESP8266.\nESP8266, LD2410 and Parts Assembly. Now, we can unplug the USB cable and wire up the LD2410C sensor module with ESP8266.\nWire the ESP8266 and LD2410 as below:\nESP8266 LD2410 RX(GPIO3) TX TX(GPIO1) RX VIN VCC GND GND Integrate ESPHome Device into Home Assistant The last step is to integrate the ESPHome device into Home Assistant.\nGet the ESPHome device\u0026rsquo;s API key in the ESPHome Dashboard, click the ⋮(three vertical dots button), and click the Show API Key to copy the key.\nWe log on to Home Assistant and configure the ESPHome device as below:\nGo to Settings. Go to Devices and Services. The ESPHome devices should appear under Discovered, click the CONFIGURE button. Paste the ESPHome device\u0026rsquo;s API key into encryption key field and click SUBMIT button. Done. Result In the end, we should get the LD2410\u0026rsquo;s reading in the Home Assistant → Settings → Devices and Services → Devices tab(on top of the webpage) → Click the ESP8266 ESPHome device.\n","permalink":"http://localhost:1313/posts/diy-human-presence-sensor-esp8266-ld2410-esphome-integrate-home-assistant/","summary":"\u003cp\u003eThe photo above is my cheap human presence sensor with ESP8266 and LD2410C mmWave radar sensor. It costs about RM 27—ESP8266-RM 9.90 and LD2410C-RM 17.61.\u003c/p\u003e\n\u003cp\u003eThis is my first time using ESPHome and LD2410. The LD2410C mmWave radio sensor module comes with Bluetooth connectivity, and Home Assistant has an integration for this sensor module. We can power the LD2410C and directly integrate the sensor module into Home Assistant via Bluetooth.\u003c/p\u003e","title":"Build Human Presence Sensor with ESP8266, LD2410 and ESPHome, Integrate into Home Assistant."},{"content":"Recently, I bought the SONOFF Zigbee 3.0 USB Dongle Plus-P with a great deal. It was RM 84.95 and dropped to RM 64.84.\nAt first, I don\u0026rsquo;t plan to use it. I don\u0026rsquo;t have a Zigbee device. Somehow, my newly brought SONOFF SwitchMan M5 smart switch has an issue with my outlet\u0026rsquo;s neutral wire. The ELCB trips immediately after I switch on the outlet\u0026rsquo;s circuit breaker. To make my life easier, I replace it with a Smaturl Zigbee Smart Switch. Now, I can use it as a Zigbee hub/coordinator and integrate it into Home Assistant.\nMy Home Assistant runs in Docker container using Docker Compose on Debian, so I will integrate my Zigbee dongle in the Docker Compose way.\nLet\u0026rsquo;s begin.\nVideo Plug and Mount Zigbee Dongle into Docker Container The first step is to plug the SONOFF Zigbee 3.0 USB Dongle Plus-P in the computer.\nAfter, we execute the command in the terminal to find the Zigbee dongle\u0026rsquo;s device path as below:\n$ sudo ls -la /dev/serial/by-id For my case, we can see that the Zigbee dongle path is /dev/ttyUSB0.\n1total 0 2drwxr-xr-x 2 root root 60 Jan 24 09:16 . 3drwxr-xr-x 4 root root 80 Jan 24 09:16 .. 4lrwxrwxrwx 1 root root 13 Jan 24 09:16 usb-ITead_Sonoff_Zigbee_3.0_USB_Dongle_Plus_f0e49294f6bded11bda96c2e38a92db5-if00-port0 -\u0026gt; ../../ttyUSB0 Then, we modify the docker-compose.yaml to mount the /dev/ttyUSB0 into the Docker container as highlighted below:\n1version: \u0026#34;3\u0026#34; 2services: 3 homeassistant: 4 container_name: homeassistant 5 image: \u0026#34;ghcr.io/home-assistant/home-assistant:stable\u0026#34; 6 volumes: 7 - ./config/homeassistant:/config 8 - /etc/localtime:/etc/localtime:ro 9 - /run/dbus:/run/dbus:ro 10 devices: 11 - /dev/ttyUSB0:/dev/ttyUSB0 12 restart: unless-stopped 13 privileged: true 14 network_mode: host We restart the Docker container for changes to take effect.\n$ docker compose restart Just in case, restart doesn\u0026rsquo;t work. Do a clean restart as command below:\n$ docker compose down $ docker compose up -d Integrate Zigbee Dongle in Home Assistant Next, configure the Zigbee dongle in Home Assistant according to below:\nGo to Settings. Click the ADD INTEGRATION button. Search Zigbee Home Automation and select it twice. Select the Zigbee dongle\u0026rsquo;s device path(/dev/ttyUSB0). Select Create a new network for network formation. Done Paring Zigbee devices Now, we can pair our Zigbee devices according to the manufacturer\u0026rsquo;s instructions.\nFor my Smatrul Zigbee Switch, long press any button until the LED indicator light blinks to enter paring mode.\nAfterward, we go back to the Home Assistant following below:\nGo to Settings. Click the ADD INTEGRATION button. Search and select Add Zigbee Device. Devices should be discovered in the page. Conclude The whole integration is more straightforward than I think. Home Assistant already has the integration of ZHA(Zigbee Home Automation) and is compatible with the chips used in SONOFF Zigbee 3.0 USB Dongle Plus-P, making the whole process just a few clicks. The little tricky part is the Zigbee dongle mounting to the Docker container. It needs a little digging for the Zigbee dongle’s device path. That’s it.\n","permalink":"http://localhost:1313/posts/integrate-sonoff-zigbee-dongle-plus-p-into-home-assistant/","summary":"\u003cp\u003eRecently, I bought the SONOFF Zigbee 3.0 USB Dongle Plus-P with a great deal. It was RM 84.95 and dropped to RM 64.84.\u003c/p\u003e\n\u003cp\u003eAt first, I don\u0026rsquo;t plan to use it. I don\u0026rsquo;t have a Zigbee device. Somehow, my newly brought SONOFF SwitchMan M5 smart switch has an issue with my outlet\u0026rsquo;s neutral wire. \u003ca href=\"https://yjchoo.github.io/blog/posts/install-smart-switch-cause-elcb-trip/\"\u003eThe ELCB trips immediately after I switch on the outlet\u0026rsquo;s circuit breaker.\u003c/a\u003e To make my life easier, I replace it with a Smaturl Zigbee Smart Switch. Now, I can use it as a Zigbee hub/coordinator and integrate it into Home Assistant.\u003c/p\u003e","title":"Integrate SONOFF Zigbee USB Dongle 3.0 Plus-P into Home Assistant."},{"content":"My washing machine has the water fill/water flow slow/water pressure low issue. It slows down the washing machine\u0026rsquo;s normal wash cycle from around 1 hour to 3 or 4 hours to complete.\nWater Inlet Valve Issue. Usually, it\u0026rsquo;s caused by the clogging washing machine\u0026rsquo;s water inlet filter. However, mine one is the water valve faulty. The water valve controls the water flow to decide when to start filling and stop the water. My water valve still functions as it should, but I think it has some blockage, causing the water to flow slowly.\nSo, I fixed it by myself. I spent about RM 15 on the water inlet valve and a whole day to replace it.\n","permalink":"http://localhost:1313/posts/fix-washing-machine-water-fill-issue/","summary":"\u003cp\u003eMy washing machine has the water fill/water flow slow/water pressure low issue. It slows down the washing machine\u0026rsquo;s normal wash cycle from around 1 hour to 3 or 4 hours to complete.\u003c/p\u003e\n\u003ch2 id=\"water-inlet-valve-issue\"\u003eWater Inlet Valve Issue.\u003c/h2\u003e\n\u003cp\u003e\u003cdiv style=\"position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;\"\u003e\n      \u003ciframe allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen\" loading=\"eager\" referrerpolicy=\"strict-origin-when-cross-origin\" src=\"https://www.youtube.com/embed/r8H9PfDlAeE?autoplay=0\u0026amp;controls=1\u0026amp;end=0\u0026amp;loop=0\u0026amp;mute=0\u0026amp;start=0\" style=\"position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;\" title=\"YouTube video\"\u003e\u003c/iframe\u003e\n    \u003c/div\u003e\n\n\u003c!-- raw HTML omitted --\u003e\u003c/p\u003e\n\u003cp\u003eUsually, it\u0026rsquo;s caused by the clogging washing machine\u0026rsquo;s water inlet filter. However, mine one is the water valve faulty. The water valve controls the water flow to decide when to start filling and stop the water. My water valve still functions as it should, but I think it has some blockage, causing the water to flow slowly.\u003c/p\u003e","title":"Fixing Washing Machine Water Fill Issue."}]